{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c05527ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Time series \n",
    "import datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "#Modules\n",
    "import wrangle as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc31884",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Model Evaluation:  These models will be evalutated using root-mean-square errorr (RMSE) and mean absolute percentage error (MAPE) on a 1 day and 3 day basis.</b>\n",
    "    <ul>\n",
    "        <li><b>RMSE</b> allows us to see the overall error of the model in the energy load units (MW).</li>\n",
    "        <li><b>MAPE</b> complements that by telling us how accurate the model is on a percentage basis.  This is important as the energy load varies greatly throughout the year, so a 1000 MW RMSE on a hot summer day will have a much lower MAPE percentage than a 1000 MW RMSE on a comfortable Saturday in the Fall.</li>\n",
    "        <li>The <b>3 day metrics</b> will tell us the overall performance of the 3 day forecast.  However, we expect the 3rd day to be less accurate than the 1st day and production models will be re-run on a daily or sub-daily basis. For that reason, we also will look at <b>1 day metrics</b> to see the model performance over the first day only.</li>\n",
    "    </ul><div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1af1ef3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Cross-Validation Notes:</b><br><br>Cross validation was performed on a sliding window.  Models were trained on <b>4 year initial windows</b>, with a <b>forecasting horizon of 3 days</b>.  Due to the large amount of data we had available, we minimized processing time by using a <b>36 day sliding offset</b>.  A 36 day offset ensured that our forecasting window started at different days of the week and rotated through different parts of the month. <br><br> The downside to this approach is that it is possible the model is not tested over more anomalous time periods (such as holidays or major weather events like Hurrican Harvey).  A smaller sliding offset (such as 1 or 2 days) would catch those time periods, however it would require much more processing time. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89655dc",
   "metadata": {},
   "source": [
    "### Prophet Models\n",
    "\n",
    "**Note:** You will notice that we re-acquire the dataframes in this section.  Prophet requires time zone naive inputs, however we wanted our explore section above to display CST time zones for readability.\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Make sure those two get prophet functions (seen in next cell) are in the main wrangle file.  I have not added them yet as I'm not sure if Greg has all his changes in there or not. - Cayt</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fdd40303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire data\n",
    "dfr = wr.get_prophet_df_w_meantemp()\n",
    "#Filter train based on CST time (EOY 2017, time zone naive UTC time is in this df)\n",
    "trainr = dfr[dfr.ds < '2018-01-01 06:00:00']\n",
    "\n",
    "#Create df w/o regression column\n",
    "train = trainr[['ds','y']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28d38226",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set metrics to evaluate\n",
    "metrics = ['rmse','mape']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273664d3",
   "metadata": {},
   "source": [
    "##### Basic Prophet model\n",
    "- Uses default Prophet settings:\n",
    "  - Auto for all seasonality\n",
    "  - No holidays\n",
    "  - No regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d15fddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:02:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f640ea12dc144a5780f4ef3ecc13a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:13:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "#Create and Fit Basic Prophet model\n",
    "model = Prophet().fit(train)\n",
    "\n",
    "#Create cross-validation matrix\n",
    "df_cv = cross_validation(model,initial='1461 days', period='36 days', horizon = '3 days')\n",
    "\n",
    "#Get 1 and 3 day model performance\n",
    "df_p_1d = performance_metrics(df_cv,rolling_window=.33,metrics=metrics)\n",
    "df_p_3d = performance_metrics(df_cv,rolling_window=1,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b6d14e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBasic Prophet model performance:\u001b[0m\n",
      "1 day rmse: 1220.0 MW\n",
      "1 day mape: 8.1%\n",
      "3 day rmse: 1302.0 MW\n",
      "3 day mape: 8.5%\n"
     ]
    }
   ],
   "source": [
    "#print model results\n",
    "print_model_results('Basic Prophet',df_p_1d,df_p_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8206aaae",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Need to add this new function to wrangle, then update the above line to reference wrangle.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94da7307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_results(name,df_p_1d,df_p_3d):\n",
    "    #Print model name\n",
    "    print(f'\\033[1m{name} model performance:\\033[0m')\n",
    "    #grab model stats\n",
    "    rmse1 = df_p_1d.loc[0,'rmse']\n",
    "    mape1 = df_p_1d.loc[0,'mape']*100\n",
    "    rmse3 = df_p_3d.loc[0,'rmse']\n",
    "    mape3 = df_p_3d.loc[0,'mape']*100\n",
    "    print(f'1 day rmse: {round(rmse1,0)} MW')\n",
    "    print(f'1 day mape: {round(mape1,1)}%')\n",
    "    print(f'3 day rmse: {round(rmse3,0)} MW')\n",
    "    print(f'3 day mape: {round(mape3,1)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7569a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('yearly',\n",
       "              {'period': 365.25,\n",
       "               'fourier_order': 10,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('weekly',\n",
       "              {'period': 7,\n",
       "               'fourier_order': 3,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('daily',\n",
       "              {'period': 1,\n",
       "               'fourier_order': 4,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seasonalities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
