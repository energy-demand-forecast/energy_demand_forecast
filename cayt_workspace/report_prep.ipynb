{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a6afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Time series \n",
    "import datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "# Ignoring warning messages from python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Modules\n",
    "import wrangle as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb219c8d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Model Evaluation:  These models will be evalutated using root-mean-square errorr (RMSE) and mean absolute percentage error (MAPE) on a 1 day and 3 day basis.</b>\n",
    "    <ul>\n",
    "        <li><b>RMSE</b> allows us to see the overall error of the model in the energy load units (MW).</li>\n",
    "        <li><b>MAPE</b> complements that by telling us how accurate the model is on a percentage basis.  This is important as the energy load varies greatly throughout the year, so a 1000 MW RMSE on a hot summer day will have a much lower MAPE percentage than a 1000 MW RMSE on a comfortable Saturday in the Fall.</li>\n",
    "        <li>The <b>3 day metrics</b> will tell us the overall performance of the 3 day forecast.  However, we expect the 3rd day to be less accurate than the 1st day and production models will be re-run on a daily or sub-daily basis. For that reason, we also will look at <b>1 day metrics</b> to see the model performance over the first day only.</li>\n",
    "    </ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a9fd1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Cross-Validation Notes:</b><br><br>Cross validation was performed on a sliding window.  Models were trained on <b>4 year initial windows</b>, with a <b>forecasting horizon of 3 days</b>.  Due to the large amount of data we had available, we minimized processing time by using a <b>36 day sliding offset</b>.  A 36 day offset ensured that our forecasting window started at different days of the week and rotated through different parts of the month. <br><br> The downside to this approach is that it is possible the model is not tested over more anomalous time periods (such as holidays or major weather events like Hurrican Harvey).  A smaller sliding offset (such as 1 or 2 days) would catch those time periods, however it would require much more processing time. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170a4d1",
   "metadata": {},
   "source": [
    "### Prophet Models\n",
    "\n",
    "**Note:** You will notice that we re-acquire the dataframes in this section.  Prophet requires time zone naive inputs, however we wanted our explore section above to display CST time zones for readability.\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Make sure those two get prophet functions (seen in next cell) are in the main wrangle file.  I have not added them yet as I'm not sure if Greg has all his changes in there or not. - Cayt</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b98893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire data\n",
    "dfr = wr.get_prophet_df_w_meantemp()\n",
    "#Filter train based on CST time (EOY 2017, time zone naive UTC time is in this df)\n",
    "trainr = dfr[dfr.ds < '2018-01-01 06:00:00']\n",
    "\n",
    "#Create df w/o regression column\n",
    "train = trainr[['ds','y']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839e73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set metrics to evaluate\n",
    "metrics = ['rmse','mape']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40336530",
   "metadata": {},
   "source": [
    "##### Basic Prophet model\n",
    "\n",
    "<div class='alert alert-success'>Uses default Prophet settings:\n",
    "<ul>\n",
    "    <li>Auto for all seasonality</li>\n",
    "    <li>No holidays</li>\n",
    "    <li>No regression</li>\n",
    "    </ul>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1e8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:02:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f640ea12dc144a5780f4ef3ecc13a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:13:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "#Create and Fit Basic Prophet model\n",
    "model = Prophet().fit(train)\n",
    "\n",
    "#Create cross-validation matrix\n",
    "df_cv = cross_validation(model,initial='1461 days', period='36 days', horizon = '3 days')\n",
    "\n",
    "#Get 1 and 3 day model performance\n",
    "df_p_1d = performance_metrics(df_cv,rolling_window=.33,metrics=metrics)\n",
    "df_p_3d = performance_metrics(df_cv,rolling_window=1,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9dbcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBasic Prophet model performance:\u001b[0m\n",
      "1 day rmse: 1220.0 MW\n",
      "1 day mape: 8.1%\n",
      "3 day rmse: 1302.0 MW\n",
      "3 day mape: 8.5%\n"
     ]
    }
   ],
   "source": [
    "#print model results\n",
    "wr.print_model_results('Basic Prophet',df_p_1d,df_p_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf399276",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Need to add this new function to wrangle, then update the above line to reference wrangle.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faed0066",
   "metadata": {},
   "source": [
    "<div class='alert alert-success'><b>Seasonality Notes:</b>\n",
    "<ul>\n",
    "    <li>The auto seasonality set a scale of 10 for the yearly, weekly and daily seasons.  Based off our industry knowledge and exploration of the data, we expect the daily and weekly seasonalities to carry a higher weight than the yearly seasonality.  In addition, we are concerned that yearly seasonality is a proxy for a temperature regressor and that including both may be detrimental to the model.</li>\n",
    "    <li>The yearly fourier order of 10 seemed quite high compared to the weekly order of 3 and daily order of 4.</li>\n",
    "    <li>We want all seasonalities to be additive.</li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8aea38",
   "metadata": {},
   "source": [
    "##### Prophet Model v2 - Hyperparameter first pass \n",
    "\n",
    "\n",
    "<div class='alert alert-success'>Prophet settings:\n",
    "<ul>\n",
    "    <li>Remove auto-seasonality</li>\n",
    "    <li>Manually add seasonality:\n",
    "    <ul>\n",
    "        <li>daily fourier order of 6, with a scale of 30</li>\n",
    "        <li>weekly fourier order of 6, with a scale of 30</li>\n",
    "        <li>yearly fourier order of 6, with a scale of 10</li>\n",
    "        <li>NOTES: choose a higher daily and weekly order and scale, while lowering yearly scale.\n",
    "        </ul>\n",
    "    </li>\n",
    "    <li>Added US Federal observed holidays</li>\n",
    "    <li>Added mean temperature regressor</li>\n",
    "    </ul>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30aaea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert Holiday work\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f75ae038",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert First Pass\n",
    "m = Prophet(yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            holidays=only_holidays)\n",
    "\n",
    "m = m.add_seasonality(name='daily', \n",
    "                      period=1, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "\n",
    "m = m.add_seasonality(name='weekly', \n",
    "                      period=7, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "m = m.add_seasonality(name='yearly', \n",
    "                      period=365.25, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=10\n",
    "                     )\n",
    "\n",
    "m = m.add_regressor('mean_temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b3d1c",
   "metadata": {},
   "source": [
    "##### Prophet post-Hyperparameter tuning\n",
    "\n",
    "**Note:** While we would have preferred to run more hyperparameter combinations all at once, we were limited by the processing time.  We chose to do smaller batches of hyperparameters so that we could perform more iterations while still maximizing the combinations.\n",
    "\n",
    "<div class='alert alert-info'><b>Hyperparameter Tuning - Round 1 - 48 models</b>\n",
    "<br><br><u>Hyperparameters:</u>\n",
    "    <ul>\n",
    "        <li>Remove yearly seasonality as it is a proxy for the temperature regressor. We suspect the two are not independent.</li>\n",
    "        <li>Keep the mean temperature as a regressor.</li>\n",
    "        <li>Try multiple scales [10,20,30] and fourier orders [2,3] for daily and weekly seasonalities</li>\n",
    "        </ul>\n",
    "\n",
    "<br><b>Results:</b> \n",
    "<ul>\n",
    "    <li>This performed significantly worse than the first pass, with the highest performing model having a 3 day MAPE of 13.2%. <b>Action:</b> Re-add in the yearly seasonality</li>\n",
    "    <li>Seasonal scales of 10 across the board performed the best - which may be due to using the default holiday and regressor scale.  <b>Action:</b> Go with lower seasonal scales. </li>\n",
    "    <li>The top performing models all had daily and weekly fourier orders of 3. <b>Action:</b> Try fourier orders of 3+.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-info'><b>Hyperparameter Tuning - Round 2 - 36 models</b>\n",
    "<br><br><u>Hyperparameters:</u>\n",
    "    <ul>\n",
    "        <li>Added yearly seasonality with scale of 5 and 10</li>\n",
    "        <li>Use a daily and weekly scale of 10</li>\n",
    "        <li>Use daily and yearly fourier orders of 3-5, and a weekly fourier order of 3 and 4.</li>\n",
    "        </ul>\n",
    "\n",
    "<br><b>Results:</b> \n",
    "<ul>\n",
    "    <li>Significant improvement in 3 day MAPE from the first round of models, with the best at 8.2%. <b>Action:</b> Keep yearly seasonality</li>\n",
    "    <li>Top models contained a daily fourier order of 5. <b>Action:</b> Try 5+ in next round. </li>\n",
    "    <li>Top models contained a yearly fourier order of 3. <b>Action:</b> Try 2 and 3 in next round. </li>\n",
    "    <li>Mixed results on yearly scale options of 5 and 10 and weekly order of 3 and 4. Slight edge for a scale of 5 and order of 3.</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-info'><b>Hyperparameter Tuning - Round 3 - 12 models</b>\n",
    "<br><br><u>Hyperparameters:</u>\n",
    "    <ul>\n",
    "        <li>Keep daily, weekly, yearly scales of 10, 10 and 5, respectively.  Try regressor scales of 10 and 15.</li>\n",
    "        <li>Use a daily fourier order of 5-7</li>\n",
    "        <li>Use yearly fourier order of 2 and 3.</li>\n",
    "        </ul>\n",
    "\n",
    "<br><b>Results:</b> \n",
    "<ul>\n",
    "    <li>Yearly fourier order of 3 consistently outperformed. <b>Action:</b> Keep yearly at 3.</li>\n",
    "    <li>Regressor scales of 10 mostly outperformed scales of 15. <b>Action:</b> Keep regressor scale of 10. </li>\n",
    "    <li>Mixed results on daily fourier order, however 5 performed best in situations with the last two bullets. <b>Action:</b> Keep daily order of 5</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-info'><b>Hyperparameter Tuning - Round 4 - 24 models</b>\n",
    "<br><br><u>Hyperparameters:</u>\n",
    "    <ul>\n",
    "        <li>Try smaller scale changes of 8 and 10 for daily, 8, 10 and 12 for weekly and 5 and 7 for yearly. Keep regressor at 10.</li>\n",
    "        <li>Use a daily fourier order of 5 and a yearly fourier order of 3</li>\n",
    "        <li>Use weekly fourier order of 3 and 5.</li>\n",
    "        </ul>\n",
    "\n",
    "<br><b>Results:</b> \n",
    "<ul>\n",
    "    <li>Weekly fourier order of 5 consistently outperformed. <b>Action:</b> Potentially try 5+.</li>\n",
    "    <li>Yearly scale of 7 consistently outperformed <b>Action:</b> Keep yearly scale of 7, consider trying 10 again on final round since it performed very closesly to 5 in the past. </li>\n",
    "    <li>Given the above bullets, daily and weekly scales of 10 performed best. <b>Action:</b> Keep at 10</li>\n",
    "    </ul>\n",
    "</div>\n",
    "\n",
    "<div class='alert alert-info'><b>Hyperparameter Tuning - Round 5 (Final) - 12 models</b>\n",
    "<br><br><u>Hyperparameters:</u>\n",
    "    <ul>\n",
    "        <li>Daily, weekly and regressor scales at 10. Yearly scales at 7 and 10.</li>\n",
    "        <li>Daily fourier order of 5, yearly fourier order of 3.  Weekly fourier order of 5-10.</li>\n",
    "        <li>US Federal Observed holidays</li>\n",
    "        <li>Mean Temperature regressor</li>\n",
    "        </ul>\n",
    "\n",
    "<br><b>Results:</b> \n",
    "<ul>\n",
    "    <li></li>\n",
    "    <li></li>\n",
    "    <li></li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95fd3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREP Holidays\n",
    "#create calendar object\n",
    "cal = USFederalHolidayCalendar()\n",
    "#get holidays as list of dates\n",
    "train_holidays = cal.holidays(start=trainr.ds.min(),end=trainr.ds.max())\n",
    "\n",
    "# Transition to dataframe with holiday, ds columns\n",
    "holiday_df = pd.DataFrame(trainr.ds)\n",
    "#For each datetime, get if it lands on a holiday\n",
    "holiday_df['holiday'] = holiday_df.ds.dt.date.astype(str).isin(train_holidays.astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e0e539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down to just the holidays\n",
    "only_holidays = holiday_df[holiday_df.holiday==1]\n",
    "#Convert that column to string\n",
    "only_holidays.holiday = only_holidays.holiday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907daa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "m = Prophet(yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            holidays=only_holidays)\n",
    "#Add seasonalities\n",
    "m = m.add_seasonality(name='daily', \n",
    "                      period=1, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "m = m.add_seasonality(name='weekly', \n",
    "                      period=7, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "m = m.add_seasonality(name='yearly', \n",
    "                      period=365.25, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=10\n",
    "                     )\n",
    "#Add Regressors\n",
    "m = m.add_regressor('mean_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ec86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "757eb079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('yearly',\n",
       "              {'period': 365.25,\n",
       "               'fourier_order': 10,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('weekly',\n",
       "              {'period': 7,\n",
       "               'fourier_order': 3,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('daily',\n",
       "              {'period': 1,\n",
       "               'fourier_order': 4,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seasonalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f368dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c54af08",
   "metadata": {},
   "source": [
    "Recommendations\n",
    "- Review acquisition/prep - find more reliable source of load data. Likely need to look at how it is written\n",
    "- Use previous weather forecasts to actual weather and difference in load to create uncertainty bands\n",
    "- Do more day type patterning for holidays\n",
    "- Run an LSTM model.  Better able to use more historical data for day type patterning, with short term historical data for time series forecasting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
