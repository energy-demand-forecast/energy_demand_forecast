{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a4a6afb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "#Time series \n",
    "import datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation\n",
    "from prophet.diagnostics import performance_metrics\n",
    "\n",
    "# Ignoring warning messages from python\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#Modules\n",
    "import wrangle as wr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb219c8d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Model Evaluation:  These models will be evalutated using root-mean-square errorr (RMSE) and mean absolute percentage error (MAPE) on a 1 day and 3 day basis.</b>\n",
    "    <ul>\n",
    "        <li><b>RMSE</b> allows us to see the overall error of the model in the energy load units (MW).</li>\n",
    "        <li><b>MAPE</b> complements that by telling us how accurate the model is on a percentage basis.  This is important as the energy load varies greatly throughout the year, so a 1000 MW RMSE on a hot summer day will have a much lower MAPE percentage than a 1000 MW RMSE on a comfortable Saturday in the Fall.</li>\n",
    "        <li>The <b>3 day metrics</b> will tell us the overall performance of the 3 day forecast.  However, we expect the 3rd day to be less accurate than the 1st day and production models will be re-run on a daily or sub-daily basis. For that reason, we also will look at <b>1 day metrics</b> to see the model performance over the first day only.</li>\n",
    "    </ul><div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a9fd1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><b>Cross-Validation Notes:</b><br><br>Cross validation was performed on a sliding window.  Models were trained on <b>4 year initial windows</b>, with a <b>forecasting horizon of 3 days</b>.  Due to the large amount of data we had available, we minimized processing time by using a <b>36 day sliding offset</b>.  A 36 day offset ensured that our forecasting window started at different days of the week and rotated through different parts of the month. <br><br> The downside to this approach is that it is possible the model is not tested over more anomalous time periods (such as holidays or major weather events like Hurrican Harvey).  A smaller sliding offset (such as 1 or 2 days) would catch those time periods, however it would require much more processing time. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3170a4d1",
   "metadata": {},
   "source": [
    "### Prophet Models\n",
    "\n",
    "**Note:** You will notice that we re-acquire the dataframes in this section.  Prophet requires time zone naive inputs, however we wanted our explore section above to display CST time zones for readability.\n",
    "\n",
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Make sure those two get prophet functions (seen in next cell) are in the main wrangle file.  I have not added them yet as I'm not sure if Greg has all his changes in there or not. - Cayt</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b98893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Acquire data\n",
    "dfr = wr.get_prophet_df_w_meantemp()\n",
    "#Filter train based on CST time (EOY 2017, time zone naive UTC time is in this df)\n",
    "trainr = dfr[dfr.ds < '2018-01-01 06:00:00']\n",
    "\n",
    "#Create df w/o regression column\n",
    "train = trainr[['ds','y']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839e73a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set metrics to evaluate\n",
    "metrics = ['rmse','mape']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40336530",
   "metadata": {},
   "source": [
    "##### Basic Prophet model\n",
    "- Uses default Prophet settings:\n",
    "  - Auto for all seasonality\n",
    "  - No holidays\n",
    "  - No regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1e8013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:30 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:02:55 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f640ea12dc144a5780f4ef3ecc13a94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:02:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:08 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:30 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:44 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:45 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:03:57 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:03:58 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:10 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:04:49 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:04:50 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:05:52 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:05:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:10 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:22 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:06:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:06:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:17 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:18 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:36 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:38 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:07:58 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:07:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:19 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:21 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:36 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:08:48 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:08:49 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:01 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:20 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:22 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:37 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:39 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:09:54 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:09:56 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:09 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:11 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:29 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:31 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:10:50 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:10:52 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:07 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:09 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:11:42 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:11:44 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:00 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:02 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:18 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:19 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:35 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:37 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:12:53 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:12:55 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:21 - cmdstanpy - INFO - Chain [1] done processing\n",
      "11:13:23 - cmdstanpy - INFO - Chain [1] start processing\n",
      "11:13:40 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    }
   ],
   "source": [
    "#Create and Fit Basic Prophet model\n",
    "model = Prophet().fit(train)\n",
    "\n",
    "#Create cross-validation matrix\n",
    "df_cv = cross_validation(model,initial='1461 days', period='36 days', horizon = '3 days')\n",
    "\n",
    "#Get 1 and 3 day model performance\n",
    "df_p_1d = performance_metrics(df_cv,rolling_window=.33,metrics=metrics)\n",
    "df_p_3d = performance_metrics(df_cv,rolling_window=1,metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d9dbcb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mBasic Prophet model performance:\u001b[0m\n",
      "1 day rmse: 1220.0 MW\n",
      "1 day mape: 8.1%\n",
      "3 day rmse: 1302.0 MW\n",
      "3 day mape: 8.5%\n"
     ]
    }
   ],
   "source": [
    "#print model results\n",
    "wr.print_model_results('Basic Prophet',df_p_1d,df_p_3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf399276",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\"><b>Final Report Prep:  Need to add this new function to wrangle, then update the above line to reference wrangle.</b></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58b3d1c",
   "metadata": {},
   "source": [
    "##### Prophet model v2 - Hyperparameter first pass \n",
    "- Remove auto-seasonality\n",
    "- manually add seasons:\n",
    "  - daily fourier order of 6, with a scale of 30\n",
    "  - weekly fourier order of 6, with a scale of 30\n",
    "  - yearly fourier order of 6, with a scale of 10\n",
    "- Added US Federal observed holidays\n",
    "- Added mean temperature regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95fd3e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PREP Holidays\n",
    "#create calendar object\n",
    "cal = USFederalHolidayCalendar()\n",
    "#get holidays as list of dates\n",
    "train_holidays = cal.holidays(start=trainr.ds.min(),end=trainr.ds.max())\n",
    "\n",
    "# Transition to dataframe with holiday, ds columns\n",
    "holiday_df = pd.DataFrame(trainr.ds)\n",
    "#For each datetime, get if it lands on a holiday\n",
    "holiday_df['holiday'] = holiday_df.ds.dt.date.astype(str).isin(train_holidays.astype(str)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e0e539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter down to just the holidays\n",
    "only_holidays = holiday_df[holiday_df.holiday==1]\n",
    "#Convert that column to string\n",
    "only_holidays.holiday = only_holidays.holiday.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907daa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the model\n",
    "m = Prophet(yearly_seasonality=False,\n",
    "            weekly_seasonality=False,\n",
    "            daily_seasonality=False,\n",
    "            holidays=only_holidays)\n",
    "#Add seasonalities\n",
    "m = m.add_seasonality(name='daily', \n",
    "                      period=1, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "m = m.add_seasonality(name='weekly', \n",
    "                      period=7, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=30\n",
    "                     )\n",
    "m = m.add_seasonality(name='yearly', \n",
    "                      period=365.25, \n",
    "                      fourier_order=6,\n",
    "                      prior_scale=10\n",
    "                     )\n",
    "#Add Regressors\n",
    "m = m.add_regressor('mean_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ec86e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "757eb079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('yearly',\n",
       "              {'period': 365.25,\n",
       "               'fourier_order': 10,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('weekly',\n",
       "              {'period': 7,\n",
       "               'fourier_order': 3,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None}),\n",
       "             ('daily',\n",
       "              {'period': 1,\n",
       "               'fourier_order': 4,\n",
       "               'prior_scale': 10.0,\n",
       "               'mode': 'additive',\n",
       "               'condition_name': None})])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.seasonalities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
